<!DOCTYPE html>
<html
  dir="ltr"
  lang="en"
  data-theme=""
><head>
  <title>
    Kevin
   
  </title>

 

  
  <meta charset="utf-8" /><meta name="generator" content="Hugo 0.145.0"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <meta
    name="description"
    content="
      Less is More


    "
  />
  
  
  
  <link
    rel="stylesheet"
    href="/css/main.min.51423ad97099a08f3a20e16d238c13adae76db7dd5e1913789bdc81143ff4cc6.css"
    integrity="sha256-UUI62XCZoI86IOFtI4wTra52233V4ZE3ib3IEUP/TMY="
    crossorigin="anonymous"
    type="text/css"
  />
  
  
  <link
    rel="stylesheet"
    href="/css/markupHighlight.min.f798cbda9aaa38f89eb38be6414bd082cfd71a6780375cbf67b6d2fb2b96491e.css"
    integrity="sha256-95jL2pqqOPies4vmQUvQgs/XGmeAN1y/Z7bS&#43;yuWSR4="
    crossorigin="anonymous"
    type="text/css"
  />
  
  <link
    rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"
    integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA=="
    crossorigin="anonymous"
  />
  
  <link rel="shortcut icon" href="/favicons/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png" />

  <link rel="canonical" href="/post/scrapy_code_review/" />

  
  
  
  
  <script
    type="text/javascript"
    src="/js/anatole-header.min.d0408165d31a17f17bba83038bf54e86121f85021bdf936382e636f0f77a952f.js"
    integrity="sha256-0ECBZdMaF/F7uoMDi/VOhhIfhQIb35NjguY28Pd6lS8="
    crossorigin="anonymous"
  ></script>

  
    
    
    <script
      type="text/javascript"
      src="/js/anatole-theme-switcher.min.ea8ebe268922ef9849261a1312cd65b640595e65251ce4c00534a176afd1ac0c.js"
      integrity="sha256-6o6&#43;Joki75hJJhoTEs1ltkBZXmUlHOTABTShdq/RrAw="
      crossorigin="anonymous"
    ></script>

  
  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://example.com/images/site-feature-image.png">
  <meta name="twitter:title" content="Scrapy">
  <meta name="twitter:description" content="Less is More">



  


  
  
  
  
  <script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "articleSection": "post",
        "name": "Scrapy",
        "headline": "Scrapy",
        "alternativeHeadline": "",
        "description": "
      
        


      


    ",
        "inLanguage": "en",
        "isFamilyFriendly": "true",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/example.com\/post\/scrapy_code_review\/"
        },
        "author" : {
            "@type": "Person",
            "name": "Kevin"
        },
        "creator" : {
            "@type": "Person",
            "name": "Kevin"
        },
        "accountablePerson" : {
            "@type": "Person",
            "name": "Kevin"
        },
        "copyrightHolder" : {
            "@type": "Person",
            "name": "Kevin"
        },
        "copyrightYear" : "2020",
        "dateCreated": "2020-12-19T21:30:26.00Z",
        "datePublished": "2020-12-19T21:30:26.00Z",
        "dateModified": "2020-12-19T21:30:26.00Z",
        "publisher":{
            "@type":"Organization",
            "name": "Kevin",
            "url": "https://example.com/",
            "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/example.com\/favicons\/favicon-32x32.png",
                "width":"32",
                "height":"32"
            }
        },
        "image": 
      [
        
        "https://example.com/images/site-feature-image.png"


      
      ]

    ,
        "url" : "https:\/\/example.com\/post\/scrapy_code_review\/",
        "wordCount" : "279",
        "genre" : [ ],
        "keywords" : [ ]
    }
  </script>



</head>
<body>
    <header><div
  class="page-top 
    animated fadeInDown

  "
>
  <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
    <span aria-hidden="true"></span>
    <span aria-hidden="true"></span>
    <span aria-hidden="true"></span>
  </a>
  <nav>
    <ul class="nav__list" id="navMenu">
      <div class="nav__links">
        
        
          
          <li>
            <a
              
              href="/"
              
              title=""
              >Home</a
            >
          </li>

        
          
          <li>
            <a
              
              href="/post/"
              
              title=""
              >Posts</a
            >
          </li>

        
          
          <li>
            <a
              
              href="/about/"
              
              title=""
              >About</a
            >
          </li>

        
          
          <li>
            <a
              
              href="/connect/"
              
              title=""
              >Connect</a
            >
          </li>

        
        
      </div>
      <li>
        
          <a class="theme-switch" title="Switch Theme">
            <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
          </a>

        
      </li>
    </ul>
  </nav>
</div>
</header>
    <div class="wrapper">
      <aside><div
  class="sidebar
    animated fadeInDown

  "
>
  <div class="sidebar__content">
    
    
    <div class="logo-title">
      <div class="title">
        <img src="/images/profile.jpg" alt="profile picture" />
        <h3 title=""><a href="/">Kevin</a></h3>
        <div class="description">
          <p>Less is More</p>
        </div>
      </div>
    </div>
    <ul class="social-links">
      
        <li>
          <a href="https://github.com/imkevinliao/imkevinliao.github.io" rel="me" aria-label="GitHub">
            <i class="fab fa-github fa-2x" aria-hidden="true"></i>
          </a>
        </li>

      
        <li>
          <a href="mailto:im.kevinliao@gmail.com" rel="me" aria-label="e-mail">
            <i class="fas fa-envelope fa-2x" aria-hidden="true"></i>
          </a>
        </li>

      
    </ul>
  </div><footer class="footer footer--sidebar">
  <div class="by_farbox">
    <ul class="footer__list">
      <li class="footer__item">
        &copy;
        
          2020-2025

        
      </li>
      
        <li class="footer__item">
          <a
            href="/imprint/"
            
            title=""
          >
            imprint
          </a>
        </li>

      
    </ul>
  </div>

</footer>
  
  <script
    type="text/javascript"
    src="/js/medium-zoom.min.44288fd315b6cda68c1f4743caad56535c0f81a5b5a672f385e82b3896575c1d.js"
    integrity="sha256-RCiP0xW2zaaMH0dDyq1WU1wPgaW1pnLzhegrOJZXXB0="
    crossorigin="anonymous"
  ></script></div>
</aside>
      <main>
        <div class="autopagerize_page_element">
          <div class="content">

  <div
    class="post 
      animated fadeInDown

    "
  >
    <div class="post-content">
      
      <div class="post-title">
        <h1>Scrapy</h1>
        
          <div class="info">
            <em class="fas fa-calendar-day"></em>
            <span class="date"
              >
                2020/12/19


              </span
            >
            <em class="fas fa-stopwatch"></em>
            <span class="reading-time">2-minute read</span>
          </div>

        
      </div><p>Scrapy创建项目:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    scrapy startproject ScrpyDirection
</span></span><span class="line"><span class="cl">    cd ScrapyDirection
</span></span><span class="line"><span class="cl">    scrapy genspider -t crawl myspider www.baidu.com #创建全站爬虫,这种创建方式下myspider.py文件中已近包含items.py直接用就好了
</span></span><span class="line"><span class="cl">    scrapy genspider myspider www.baidu.com #创建 一般/普通 爬虫
</span></span></code></pre></div><p>Scrapy快速启动:(创建start.py文件)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    os.system(&#39;cls&#39;) # 终端清屏
</span></span><span class="line"><span class="cl">    os.chdir( r&#34;D:\SpiderDirection&#34;)
</span></span><span class="line"><span class="cl">    os.system(&#34;scrapy crawl YourSpiderName&#34;)
</span></span><span class="line"><span class="cl">    os.system(&#34;scrapy crawl YourSpiderName -s JOBDIR=Remain/001&#34;) # 提高改进
</span></span></code></pre></div><p>Scrapy数据抽取写法:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    //*[@class=&#34;title&#34;]//text() 提取class=title标签下的所有文本
</span></span><span class="line"><span class="cl">    ./div[id=&#34;mainn&#34;]  即xpath提取了一个xpath路径，然后继续往下提取文本，拼接xpath时使用，一般没必要.
</span></span><span class="line"><span class="cl">    //a/@href 提取所有a标签的href属性
</span></span><span class="line"><span class="cl">    item[&#39;domain_id&#39;] = response.xpath(&#39;//input[@id=&#34;sid&#34;]/@value&#39;).get()
</span></span><span class="line"><span class="cl">    item[&#39;name&#39;] = response.xpath(&#39;//div[@id=&#34;name&#34;]&#39;).get()
</span></span><span class="line"><span class="cl">    item[&#39;description&#39;] = response.xpath(&#39;//div[@id=&#34;description&#34;]&#39;).get()
</span></span><span class="line"><span class="cl">    contain=&#39;&#39;.join(contain).strip() #list变成str
</span></span><span class="line"><span class="cl">    response.content.decode(&#39;utf-8&#39;);response.encoding;(一个是手动解码,一个是自动解码)
</span></span><span class="line"><span class="cl">    dic1={&#34;name&#34;:&#34;youran&#34;,&#34;num&#34;:&#34;170423&#34;};dict2=dict(name=&#34;youran&#34;,num=&#34;170423&#34;).字典的两种创建方式.
</span></span></code></pre></div><p>数据持久化部分:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl">    <span class="n">with</span> <span class="n">open</span><span class="p">(</span><span class="s2">&#34;allowed_domains.txt&#34;</span><span class="p">,</span> <span class="s1">&#39;a+&#39;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="n">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">m_str</span><span class="p">)</span>  
</span></span><span class="line"><span class="cl">    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">with</span> <span class="n">open</span><span class="p">(</span><span class="s2">&#34;file.zip&#34;</span><span class="p">,</span><span class="s2">&#34;wb&#34;</span><span class="p">)</span> <span class="n">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">#jsonVersion1.0</span>
</span></span><span class="line"><span class="cl">    <span class="n">from</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">exporters</span> <span class="n">import</span> <span class="n">JsonLinesItemExporter</span>
</span></span><span class="line"><span class="cl">    <span class="k">class</span> <span class="n">QidianPipeline</span><span class="p">(</span><span class="n">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">=</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;qidian.json&#39;</span><span class="p">,</span><span class="s1">&#39;wb&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">exporter</span><span class="o">=</span><span class="n">JsonLinesItemExporter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="p">,</span><span class="n">ensure_ascii</span><span class="o">=</span><span class="n">False</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">exporter</span><span class="o">.</span><span class="n">export_item</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">item</span>  <span class="c1">#这里要注意最好是return item，因为如果pipelines中写了几个，必须返回给其他pipeline使用</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">#jsonVersion2.0(官方示例写法)</span>
</span></span><span class="line"><span class="cl">    <span class="n">import</span> <span class="n">json</span>
</span></span><span class="line"><span class="cl">    <span class="k">class</span> <span class="n">QidianPipeline</span><span class="p">(</span><span class="n">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">=</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;qidian.json&#39;</span><span class="p">,</span><span class="s1">&#39;w&#39;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">line</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">item</span><span class="p">,</span><span class="n">ensure_ascii</span><span class="o">=</span><span class="n">False</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">item</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>  
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">#保存为txt</span>
</span></span><span class="line"><span class="cl">    <span class="k">class</span> <span class="n">TextPipeline</span><span class="p">(</span><span class="n">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">pass</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">with</span> <span class="n">open</span><span class="p">(</span><span class="s2">&#34;a.txt&#34;</span><span class="p">,</span><span class="s2">&#34;a&#34;</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s2">&#34;utf-8&#34;</span><span class="p">)</span> <span class="n">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">title</span><span class="o">=</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                <span class="n">contain</span><span class="o">=</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;contain&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">title</span><span class="o">+</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">+</span><span class="n">contain</span><span class="o">+</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">item</span>
</span></span></code></pre></div><p>About items.py: 这部分可以自己写,items本质就是字典,写个字典将数据传给pipeline处理也是一样的.<br>
举例：name = scrapy.Field()</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">About settings.py 
</span></span><span class="line"><span class="cl">    ROBOTSTXT_OBEY = False #不遵守爬虫协议，改False，默认True
</span></span><span class="line"><span class="cl">    # 默认注释, 取消之, 并增加user-agent:
</span></span><span class="line"><span class="cl">    DEFAULT_REQUEST_HEADERS = {
</span></span><span class="line"><span class="cl">    &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;,
</span></span><span class="line"><span class="cl">    &#39;Accept-Language&#39;: &#39;en&#39;,
</span></span><span class="line"><span class="cl">    &#39;User-Agent&#39;:&#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36&#39;,
</span></span><span class="line"><span class="cl">    }
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    ITEM_PIPELINES = {
</span></span><span class="line"><span class="cl">    &#39;qidian.pipelines.TextPipeline&#39;: 300,#开启这一项，yield item 数据才会进入pipelines，需要pipeline处理数据就开启，
</span></span><span class="line"><span class="cl">    &#39;qidian.pipelines.JsonPipeline&#39;: 400,#数字越小越先执行,如果这里开了多个pipelines，那么pipelines文件中必须也含有这些所有的
</span></span><span class="line"><span class="cl">    }
</span></span><span class="line"><span class="cl">    DOWNLOAD_DELAY = 2 #下载延时, 支持浮点数据.
</span></span><span class="line"><span class="cl">    DOWNLOAD_TIMEOUT = 15  # 下载超时
</span></span><span class="line"><span class="cl">    RETRY_ENABLED = True # 尝试次数
</span></span><span class="line"><span class="cl">    RETRY_TIMES = 3
</span></span><span class="line"><span class="cl">    DEPTH_LIMIT= 3 # 设置爬取深度
</span></span></code></pre></div><p>进阶部分:
为了避免爬取过程异常退出而导致重新爬取采取如下措施:项目目录下要有Remain文件夹.命令:scrapy crawl  &lt;爬虫名&gt;  -s JOBDIR=Remain/001;继续运行:scrapy crawl &lt;爬虫名&gt;  -s JOBDIR=remain/001 .备注:需要重新爬取就换个文件如002就行了.&lt;os.system(&ldquo;scrapy crawl myspider -s JOBDIR=Remain/001&rdquo;)&gt;.<br>
Scrapy爬虫以项目目录为基准目录.即scrapy startproject ScrpyDirection,所以相对路径也是基于该目录.<br>
allowed_domains = [&lsquo;www.baidu.com&rsquo;] #允许域影响yield则注释掉,这个对全站爬虫Rules部分有影响,建议注释掉.<br>
yield scrapy.Request(next_url,callback=self.parse,dont_filter=True)#普通爬虫才用这个把下个爬取链接给调度器,dont_filter=True如果缺少将不会跟进爬取，就是只爬一次，不继续往下爬.<br>
yield item #item必须是字典<br>
pipelines这个组件数据持久化貌似是数据全部爬取完毕再一次性写入,这个问题很大.应该一边爬取一边写入才合理.<br>
item=QidianItem(book_name=book_name,book_intro=book_intro).使用items.py.<br>
start_urls:全站爬虫可以指定多个初始url.</p>
<p>其他代码:</p>
<p>如果不存在该文件夹则创建</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">import os 
</span></span><span class="line"><span class="cl">main_path=&#34;./Image&#34; 
</span></span><span class="line"><span class="cl">if  not os.path.exists(main_path):
</span></span><span class="line"><span class="cl">    os.makedirs(main_path)
</span></span></code></pre></div><p>全站爬虫rules部分解析</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">rules = (
</span></span><span class="line"><span class="cl">        Rule(LinkExtractor(allow=&#34;&lt;正则表达式,当然,还可以写deny(禁止)的规则&gt;&#34;),follow=True),
</span></span><span class="line"><span class="cl">        Rule(LinkExtractor(allow=&#34;.+book\.qidian\.com/info/\d*&#34;), callback=&#39;parse_detail&#39;, follow=False),
</span></span><span class="line"><span class="cl">        #follow=True是指如果页面含有符合allow正则的链接就继续提取到调度器
</span></span><span class="line"><span class="cl">        #callback=parse_item,系统默认的.警告:parse_item这个方法不能复写,这是因为scrapy框架决定,建议注释掉或删掉(最好放着别管).
</span></span><span class="line"><span class="cl">    )
</span></span></code></pre></div><p>利用PIL库下载图片,更漂亮的写法.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl"> def down_image_b(self,url):
</span></span><span class="line"><span class="cl">        import requests
</span></span><span class="line"><span class="cl">        from PIL import Image
</span></span><span class="line"><span class="cl">        from io import BytesIO
</span></span><span class="line"><span class="cl">        main_path=&#34;./image&#34;
</span></span><span class="line"><span class="cl">        if  not os.path.exists(main_path):
</span></span><span class="line"><span class="cl">            os.makedirs(main_path)
</span></span><span class="line"><span class="cl">        response = requests.get(url)
</span></span><span class="line"><span class="cl">        image = Image.open(BytesIO(response.content))
</span></span><span class="line"><span class="cl">        image.save(&#39;./image/f.jpg&#39;)
</span></span></code></pre></div></div>
    <div class="post-footer">
      <div class="info">
        

        
      </div>
    </div>

    
  </div>


          </div>
        </div>
      </main>
    </div><footer class="footer footer--base">
  <div class="by_farbox">
    <ul class="footer__list">
      <li class="footer__item">
        &copy;
        
          2020-2025

        
      </li>
      
        <li class="footer__item">
          <a
            href="/imprint/"
            
            title=""
          >
            imprint
          </a>
        </li>

      
    </ul>
  </div>

</footer>
  
  <script
    type="text/javascript"
    src="/js/medium-zoom.min.44288fd315b6cda68c1f4743caad56535c0f81a5b5a672f385e82b3896575c1d.js"
    integrity="sha256-RCiP0xW2zaaMH0dDyq1WU1wPgaW1pnLzhegrOJZXXB0="
    crossorigin="anonymous"
  ></script></body>
</html>
